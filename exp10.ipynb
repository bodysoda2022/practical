{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Generative Adversarial Network (GAN) on CIFAR-10\n",
       "\n",
       "This notebook demonstrates how to build and train a simple GAN for image generation using the CIFAR-10 dataset."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import tensorflow as tf\n",
       "from tensorflow.keras import layers\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Load and Normalize CIFAR-10 Data"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def load_real_images():\n",
       "    (x_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
       "    x_train = (x_train - 127.5) / 127.5\n",
       "    return x_train"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Build Generator"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def build_generator():\n",
       "    model = tf.keras.Sequential()\n",
       "    model.add(layers.Dense(256, input_shape=(100,)))\n",
       "    model.add(layers.LeakyReLU(alpha=0.2))\n",
       "    model.add(layers.BatchNormalization(momentum=0.8))\n",
       "    model.add(layers.Dense(512))\n",
       "    model.add(layers.LeakyReLU(alpha=0.2))\n",
       "    model.add(layers.BatchNormalization(momentum=0.8))\n",
       "    model.add(layers.Dense(1024))\n",
       "    model.add(layers.LeakyReLU(alpha=0.2))\n",
       "    model.add(layers.BatchNormalization(momentum=0.8))\n",
       "    model.add(layers.Dense(32 * 32 * 3, activation='tanh'))\n",
       "    model.add(layers.Reshape((32, 32, 3)))\n",
       "    return model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Build Discriminator"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def build_discriminator():\n",
       "    model = tf.keras.Sequential()\n",
       "    model.add(layers.Flatten(input_shape=(32, 32, 3)))\n",
       "    model.add(layers.Dense(512))\n",
       "    model.add(layers.LeakyReLU(alpha=0.2))\n",
       "    model.add(layers.Dense(256))\n",
       "    model.add(layers.LeakyReLU(alpha=0.2))\n",
       "    model.add(layers.Dense(1, activation='sigmoid'))\n",
       "    return model"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Compile GAN"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def compile_gan(generator, discriminator):\n",
       "    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
       "    discriminator.trainable = False\n",
       "    gan_input = layers.Input(shape=(100,))\n",
       "    generated_image = generator(gan_input)\n",
       "    gan_output = discriminator(generated_image)\n",
       "    gan = tf.keras.models.Model(gan_input, gan_output)\n",
       "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
       "    return gan"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Training Loop"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def train_gan(generator, discriminator, gan, epochs=1000, batch_size=64, save_interval=200):\n",
       "    x_train = load_real_images()\n",
       "    half_batch = batch_size // 2\n",
       "    for epoch in range(epochs):\n",
       "        idx = np.random.randint(0, x_train.shape[0], half_batch)\n",
       "        real_images = x_train[idx]\n",
       "        noise = np.random.normal(0, 1, (half_batch, 100))\n",
       "        fake_images = generator.predict(noise)\n",
       "        d_loss_real = discriminator.train_on_batch(real_images, np.ones((half_batch, 1)))\n",
       "        d_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((half_batch, 1)))\n",
       "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
       "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
       "        valid_y = np.array([1] * batch_size)\n",
       "        g_loss = gan.train_on_batch(noise, valid_y)\n",
       "        if epoch % save_interval == 0:\n",
       "            print(f\"Epoch {epoch} / {epochs} [D loss: {d_loss[0]}] [G loss: {g_loss}]\")\n",
       "            save_images(generator, epoch)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Save Generated Images"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def save_images(generator, epoch, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
       "    noise = np.random.normal(0, 1, (examples, 100))\n",
       "    generated_images = generator.predict(noise)\n",
       "    generated_images = 0.5 * generated_images + 0.5\n",
       "    plt.figure(figsize=figsize)\n",
       "    for i in range(examples):\n",
       "        plt.subplot(dim[0], dim[1], i+1)\n",
       "        plt.imshow(generated_images[i])\n",
       "        plt.axis('off')\n",
       "    plt.tight_layout()\n",
       "    if not os.path.exists(\"gan_images\"):\n",
       "        os.makedirs(\"gan_images\")\n",
       "    plt.savefig(f\"gan_images/gan_image_{epoch}.png\")\n",
       "    plt.close()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## Build and Train the GAN"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "generator = build_generator()\n",
       "discriminator = build_discriminator()\n",
       "gan = compile_gan(generator, discriminator)\n",
       "train_gan(generator, discriminator, gan)"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "name": "python"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 2
   }
   
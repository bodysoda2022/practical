{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')  # Only 'punkt' needed for sentence tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BERT components\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    return nltk.sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bert_embedding(sentence):\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokens)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractive_summary(text, num_sentences=3):\n",
    "    sentences = preprocess_text(text)\n",
    "    sentence_embeddings = np.array([get_bert_embedding(sent) for sent in sentences])\n",
    "    \n",
    "    similarity_matrix = cosine_similarity(sentence_embeddings)\n",
    "    sentence_scores = similarity_matrix.sum(axis=1)\n",
    "    \n",
    "    ranked_indices = np.argsort(sentence_scores)[-num_sentences:]\n",
    "    return \" \".join([sentences[i] for i in sorted(ranked_indices)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Artificial Intelligence (AI) is a rapidly advancing field that aims to create intelligent\n",
    "machines. It involves various subfields such as machine learning, deep learning, and natural language\n",
    "processing. AI is used in numerous applications including healthcare, finance, and autonomous systems.\n",
    "With the increasing availability of data and computational power, AI continues to make remarkable\n",
    "progress. However, ethical considerations and biases remain significant challenges in AI development.\"\"\"\n",
    "\n",
    "summary = extractive_summary(text, num_sentences=2)\n",
    "print(\"Generated Summary:\\n\" + summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
